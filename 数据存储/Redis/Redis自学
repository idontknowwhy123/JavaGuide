补充：redis是什么？
     redis是一个开源的高性能键值对的内存数据库，可以用作数据库、缓存、消息中间件。它是一种NoSQL的数据库
     redis作为一个内存数据库：
     1、性能优秀、数据在内存中，读写速度非常快，每秒能支持10W次的读写操作
     2、单进程单线程，是线程安全的，采用IO多路复用机制
     3、丰富的数据类型：支持字符串string,哈希hash，列表list,集合set,有序集合sorted set
     4、支持数据持久化
     5、通过主从复制和哨兵来提示它的高可用
     6、可以用作分布式锁
     7、可以用作消息中间件，支持发布订阅
     
-### redis为什么那么快
   1、绝大部分请求都是对内存进行操作，读写速度非常快，每秒支持10W次读写操作
   2、使用多路I/O复用模型，非阻塞IO
   3、采用单线程，避免了不必要的上下文切换和竞争条件
   
   什么是多路I/O复用模型？  
   1、多路分离函数select
   用户首先将需要进行的IO操作的socket添加到select当中，然后用户线程会不断的去轮询这些socket是否被激活，当数据到达时，socket被激活，用户线程正式发起read请求，读取数据并继续执行。
   使用select以后最大的优势是用户可以在一个线程内同时处理多个socket的IO请求。用户可以注册多个socket，然后不断地调用select读取被激活的socket
    
   2、IO多路复用模型
   通过Reactor的方式，可以将用户线程轮询IO操作状态的工作统一交给handle_events事件处理器进行处理。用户线程注册事件处理器之后可以继续执行做其他的工作（异步，提高CPU利用率），
   而Reactor线程里面事件处理器负责调用内核的select函数检查socket状态。当有socket被激活时，则通知相应的用户线程（或执行用户线程的回调函数），执行handle_event进行数据读取、处理的工作。
     
-### 一.redis缓存穿透以及解决方案
https://www.cnblogs.com/lingyejun/p/10087135.html
缓存穿透：是指查询一个根本不存在的数据，缓存层和存储层都不会命中，从而失去了缓存保护后端存储的意义

解决办法：
 1.缓存空对象
   有个需要考虑的问题：
   空值做了缓存，意味着缓存层存了更多的键，需要更多的内存空间，所以需要给这类空值数据设置一个比较短的过期时间
 
 2.布隆过滤器拦截

   2.1、布隆过滤器的原理
     2.1.1、布隆过滤器的数据结构
           布隆过滤器是一个bit数组，如果将一个值映射到布隆过滤器中，我们需要将这个值通过多个哈希函数生成多个哈希值，并将每个哈希值指向的
           bit位置为1，例如将“baidu”通过三个不同的哈希函数计算出三个不同的值1,4,7，然后将bit数组上对应1,4,7这三个值对应的bit位置为1，
           如果我们现在查询“tencent”这个值是否存在，我们通过这三个函数发现它对应的哈希值是1,4,8，结果发现bit位为8的这个位置对应的bit值
           为0，则说明“tencent”这个值肯定不存在，当我查询“baidu”时，发现其对应的hash值分别为1,4,7,在bit数组上对应的bit位都为1，但是我们
           现在只能说"baidu"这个值只是可能存在，因为这三个bit位的值为1有可能是其他值通过hash函数将其设置的。
           参考文献：https://www.jianshu.com/p/2104d11ee0a2

   2.2、布隆过滤器优点（hashmap在存储数据量较大的情况下，考虑到负载因子的存在，通常空间是不能用满的，这样的需要的内存空间大小就变得很可观了）
      2.2.1、它的空间效率和查询时间都远远超过一般的算法
      2.2.2、布隆过滤器不需要存储元素本身，适用于对存储数据需要严格保密的场景
   
   2.3、布隆过滤器缺点
      2.3.1、随着存入的元素数量增加，误算率随之增加。但是如果元素数量太少，则使用散列表足矣。
      2.3.2、一般情况下不能从布隆过滤器中删除元素，为什么？因为你要删除的元素对应的哈希值可能和集合中的某个元素的哈希值是相同的，一旦删除会导致其他元素也被删除
             另外，一般情况下不能从布隆过滤器中删除元素. 我们很容易想到把位数组变成整数数组，每插入一个元素相应的计数器加 1, 这样删除元素时将计数器减掉就可以了。
             然而要保证安全地删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面. 这一点单凭这个过滤器是无法保证的。另外计数器回绕也会造成问题
   
   2.4、如何选择哈希函数个数和布隆过滤器长度
       2.4.1、哈希函数个数：哈希函数越多则bit位置为1的速度越快，
                         

-###二.缓存击穿以及解决方案

定义：缓存中某个热点key在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，
这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

解决方案：
1.使用互斥锁（分布式场景那就是分布式锁）
就是只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据就可以了

2.永不过期
我们把过期时间存在key对应的value里，如果发现过期了，通过一个后台的异步线程进行缓存的构建
(其实就是每次命中缓存之后, 都去检查一下value里面保存的过期时间。发现快要过期了就从新构建一下数据。当然 Key 是不变的。)

从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。
原理：https://www.cnblogs.com/chengege/p/11073166.html

-###三.缓存雪崩
定义：缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。
事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。（主从+哨兵模式或集群模式）
     选择合适的内存淘汰策略->缓存的过期时间应该随机均匀分布，防止某一个时刻大面积的缓存失效。
事中：本地ehcache缓存 + hystrix限流&降级，避免MySQL崩掉
     当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心业务正常运作或高效运作。
事后：利用 redis 持久化机制将保存的数据尽快恢复到缓存
![](https://camo.githubusercontent.com/5026cff9341b3049578f9a05bdf60b2ec62f28d3/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d32352f363037383336372e6a7067)

补充：1.缓存的过期时间应该随机均匀分布，防止某一个时刻大面积的缓存失效
     2.加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间key是锁着的，这是过来1000个请求999个都在阻塞的。同样会导致用户等待超时，这是个治标不治本的方法！

代码实现：https://blog.csdn.netwu/article/details/80052617?utm_medium=distribute.pc_relevant_right.none-task-blog-BlogCommendFromMachineLearnPai2-5.nonecase&depth_1-utm_source=distribute.pc_relevant_right.none-task-blog-BlogCommendFromMachineLearnPai2-5.nonecase
  
-### 五.redis的数据结构及使用场景
  1. String
常用命令: set,get,decr,incr,mget 等。

String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。 常规key-value缓存应用； 常规计数：微博数，粉丝数等。

  2.Hash
常用命令： hget,hset,hgetall 等。

Hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以Hash数据结构来存储用户信息，商品信息等等。比如下面我就用 hash 类型存放了我本人的一些信息：

key=JavaUser293847
value={
  “id”: 1,
  “name”: “SnailClimb”,
  “age”: 22,
  “location”: “Wuhan, Hubei”
}

   3.list

list 就是链表，Redis list 的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的list结构来实现。

Redis list 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。

另外可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分页查询，这个很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高。

  4.set
  set 对外提供的功能与list类似是一个列表的功能，特殊之处在于 set 是可以自动排重的。

当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。

比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程，具体命令如下：

sinterstore key1 key2 key3 将交集存在key1内
 
  5.sortSet
 和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。

 举例： 在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用 Redis 中的 SortedSet 结构进行存储

 zset存在两种编码方式：如果满足如下两种条件选用ziplist编码，否则使用skiplist编码
                    （1）、元素数量小于128个
                    （2）、所有member的长度都小于64字节
     1、ziplist：第一个节点保存的是member，第二个节点保存的是score,ziplist集合里面的元素按照score从小到大的顺序进行排序,查找的时间复杂度是O(N),整体存储结构
               zlbytes:ziplist的长度（字节）
                zltail:ziplist最后一个节点的偏移量，方便我们查找最后一个元素
                 zllen:ziplist节点的个数
                 entry:节点，用于存放真正的数据项
                 zlend:用于标记ziplist的结尾
                 []!(https://img2018.cnblogs.com/i-beta/1637947/202001/1637947-20200108103030972-681210699.png
               
     2、skiplist:包含一个字典和跳跃表，跳跃表按照score从小到大的顺序保存着所有的集合元素，字典则保存着从member到score的映射关系，查找的时间复杂度是O(logN),删除，插入的时间
                 复杂度也是O(logN),简单来说，是一种基于并联的链表，也是链表中的一种，只不过在链表的基础上增加了跳跃的功能，正是这个跳跃的功能，保证了在查找元素时能够提供O(logN）
                 的时间复杂度。
                 (1)、大致的查找原理
                 指的就是除了最下面第一层链表以外，还会产生若干层稀疏的链表，这些链表的指针故意跳过了一些节点（越高层的链表跳过的节点越多），这就使得我们在链表中查找数据时，
                 优先去高层的链表中去查找数据，然后逐层降低，最终降到第一层节点精准的定位到数据，在这个过程中，我们跳过了一些节点，从而加快了查找的速度
                 （2）、为什么不能确定相邻两层节点个数的比例关系
                 skiplist并不要求上下相邻两层链表之间的节点个数有严格的比例对应关系，原因是每次新插入一个节点，就会打乱这个比例关系，如果要维持这种对应关系，就需要把新插入节点
                 后面的节点重新进入调整，这样就会把时间复杂度重新蜕化成O(n)
                 （3）、如果不确定相邻两层节点的个数比例关系，那每层链表的节点数目怎么确定呢？
                 为每个节点随机的出一个层数，例如：一个节点的随机层数是3，那么就把这个节点链入到第一层到第三层的链表中，这样做的好处是，每插入一个新的节点，只需要随机生成一个链入层数，
                 插入时只需要修改插入节点前后的指针，而不需要对很多节点都进行调整，这就降低了插入的时间复杂度，这让它在插入性能上明显优于平衡二叉树的方案。
                 （4）、redis里面执行插入操作计算随机层数的算法
                      * 首先每个节点都会存在于第一层链表中
                      * 如果当前节点存在于第i层(1=<i<MaxLevel)链表中，那么当前节点存在于第i+1层链表中的概率为p
                      * 链表的最大层数不允许超过MaxLevel
                      伪函数：
                      randomlevel()
                      level := 1
                      //random返回一个[0,1]的随机数
                      while random() < p and level < MaxLevel
                      level := level + 1
                      return level
                      注：在redis里面p=1/4，MaxLevel=32
                  （5）skiplist与hash表，平衡树的对比
     
     
https://www.cnblogs.com/yuanfang0903/p/12165394.html
https://blog.csdn.net/weixin_38008100/article/details/94629753?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control

 
 -### 六，redis的过期策略和数据淘汰策略

Redis中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如我们一般项目中的 token 或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。

我们 set key 的时候，都可以给一个 expire time，就是过期时间，通过过期时间我们可以指定这个 key 可以存活的时间。

如果假设你设置了一批 key 只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？

定期删除+惰性删除。

通过名字大概就能猜出这两个删除方式的意思了。

定期删除：redis默认是每隔 100ms 就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，
每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！

惰性删除 ：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，你在获取key时，redis会判断一些这个key是否过期，
如果过期则会删除，没有过期则会返回。这就是所谓的惰性删除，也是够懒的哈！但是仅仅通过设置过期时间还是有问题的。我们想一下：如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，
此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？
 
redis提供6种数据淘汰策略：

volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）.
allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
no-enviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧

-### LRU算法
   https://blog.csdn.net/WhereIsHeroFrom/article/details/86501571?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5&utm_source=distribute.
   pc_relevant.none-task-blog-BlogCommendFromBaidu-5
   1.LRU算法的核心：如果一个数据在最近一段时间内没有被访问到，那么它在将来被访问的可能性也很小。换言之，当内存达到极限时，应该把内存中最久没有被访问的数据淘汰掉。
   2.LRU算法的原理：每个对象每次被访问时都会记录下当前服务器LRU时钟作为该对象的LRU时钟，然后用服务器的LRU时钟减去该对象的LRU时钟则是该对象没有被访问的时间间隔（也称空闲时间），
                   空闲时间最大的则是需要被淘汰掉的对象

   3.LRU算法的回收流程：
     3.1、从redis内存中随机选取一定数量的键
     3.2、然后通过一个长度为16的回收池对这些键对进行筛选(具体就是回收池的更新逻辑)，筛选的规则就是根据空闲时间的大小进行排列
     3.3、筛选出空闲时间最大的键将其删除，并且将其从回收池中移除

  4.回收池的更新：LRU算法的核心，就是从redis内存中随机选取一定数量的键，然后将这些键缓存在sample数组中，然后一个个取出来和回收池中的键按照空闲时间进行对比，更新回收池
                 更新的过程主要是先遍历整个回收池，找到键的实际插入位置k；
                 4.1、如果回收池已满，且该键的空闲时间最小，则无需处理
                 4.2、如果回收池已满，且该键的空闲时间不是最小，则将索引位置为k的前面元素都向前移动一位，并在索引位置k插入该键
                 4.3、如果回收池未满，且索引位置k没有元素，则直接将键插入到位置k
                 4.4、如果回收池未满，且索引位置k有元素，则将索引位置为k及以后的元素都向后移动一位，并在索引位置k插入该键
              

-###redis分布式锁
  1.基于zoopkeeper的实现
    
  1.1、锁的获取
       1.1.1、首先会在Zookeeper当中创建一个持久节点ParentLock。当第一个客户端想要获取锁时，需要在这个持久节点下面创建一个临时顺序节点Lock1,然后客户端1查找ParentLock下面所有的临时顺序节点
              并进行排序，判断自己创建的节点Lock1是不是顺序最靠前的节点，如果是则获取锁成功。
       1.1.2、这时候，如果有个客户端2也来获取锁，则在ParentLock下面再创建一个临时顺序节点Lock2,客户端2再查找ParentLock下面的所有临时顺序节点并排序，并判断Lock2这个节点是不是所有节点
              里面排序最靠前的那个节点，结果发现不是，然后在排序比他靠前的那个节点Lock1注册一个Watcher，用于监听Lock1节点是否存在，然后客户端2进入等待状态
       1.1.3、这个时候，如果客户单3也来获取锁，也会和客户端2一样进入等待状态，并且给Lock2注册一个Watcher,用于监听Lock2节点是否存在
       
              这样一来，客户端1获取到了锁，客户端2监听了Lock1，客户端3监听了Lock2，从而形成了一个等待队列

1.2、锁的释放
       锁的释放分为两种情况：
       1.2.1、任务完成，客户端显示释放
              当任务完成时，客户端1会显示调用删除节点Lock1的指令
       1.2.2、任务执行过程中，客户端崩溃
              当客户端崩溃时，会断开与Zookeeper服务端的连接，根据临时节点的特性，相关联的节点Lock1也会随之自动删除
       
       当Lock1节点被删除时，客户端2会立即收到通知，这时候客户端2会再次查询ParentLock下面的所有节点，并判断Lock2节点是不是顺序最靠前的节点，
       如果是，则获取锁成功。
        
       参考链接：https://blog.csdn.net/wuzhiwei549/article/details/80692278?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1
       
  2.redission分布式锁原理及实现
  RLock lock = redission.getLock("myLock");
  lock.lock();
  lock.unlock();
  
  2.1、加锁机制
  客户端需要加锁，客户端会从集群中根据hash节点选择一台机器，然后发送一段lua脚本到redis上：
  为啥要是有lua脚本?
  为了保证这段复杂业务逻辑执行的原子性
  "if (redis.call('exist',KEYS[1]) == 0) then " +
      "redis.call('hset',KEYS[1],ARGV[2],1); " +
      "redis.call('pexpire',KEYS[1],AGRV[1]); " +
      "return nil; " +
   "end; " +
   if (redis.call('hexists',KEYS[1]),ARGV[2] == 1) then " +
      "redis.call('hincrby',KEYS[1],ARGV[2],1); " +
      "redis.call('pexpire',KEYS[1],AGRV[1]); " +
      "return nil; " +
   "end; " +
   "return redis.call('pttl',KEYS[1]);"
   其中，KEYS[1]代表加锁的key,例如RLock lock = redission.getLock("myLock");对应的锁key就是"myLock"
   ARGV[1]代表的是锁默认的生存时间30S，AGRV[2]代表的是加锁的客户端ID
   加锁步骤：
     2.1.1、是否需要加锁？
            第一行if语句就是用"exist myLock"命令判断一下，如果你要加锁的那个锁key不存在的话，你就进行加锁
     2.1.2、如何加锁？
            执行命令hset myLock 8743c9c0-0795-4907-87fd-6c719a6b4586:1 1,这个命令执行后，会设置一个hash数据结构
            myLock:
            {
             "8743c9c0-0795-4907-87fd-6c719a6b4586:1" : 1
            }
            上述结果代表客户端8743c9c0-0795-4907-87fd-6c719a6b4586:1对myLock这个锁完成了一次加锁
      2.1.3、设置超时时间
             接着会执行"pexpire myLock 30000"命令，设置myLock这个锁的生存时间是30秒
       
    2.2、锁的互斥机制
         如果这时又来了一个客户端2执行相同的lua脚本对myLock加锁
      2.2.1、是否需要加锁？
             第一行if语句用"exist myLock"命令判断一下，发现myLock这个锁已经存在了，就进入第二个判断
      2.2.2、第二if语句判断是key为"myLock"的hash数据结构中是否包含客户端2，如果不包含，则进入第三个逻辑
      2.2.3、然后客户端2会获取到pttl myLock返回的一个数字，这个数字代表myLock这个锁的剩余生存时间。
      2.2.4、最后客户端2会进入一个while循环，不停的尝试加锁。
      
    2.3、watch dog自动延期机制
         客户端1加锁的锁key默认的超时时间是30s，如果过了30s，客户端1还没有处理完业务，还需要继续持有这个锁，就可以开启一个watch dog
         看门狗线程，这个线程会每隔10s检查一下，如果客户端1还持有锁的话，那么就会不断延长锁key的超时时间
         
    2.4、锁的可重入机制
         客户端1已经持有了myLock锁，然后进行可重入的加锁
         2.4.1、首先还是第一个if语句判断"myLock"这个锁是否存在，已经存在，则进入第二个判断
         2.4.2、通过myLock这个锁的hash数据结构判断是否是客户端1持有了myLock锁，发现客户端1确实持有这把锁
         2.4.3、接着就会执行incrby myLock 8743c9c0-0795-4907-87fd-6c71a6b4586:1 1命令将客户端1的加锁次数进行加1，这个时候的myLock
                数据结构就是：
                myLock:
                {
                 "8743c9c0-0795-4907-87fd-6c719a6b4586:1" : 2
                }
                其中客户端ID对应的就是加锁次数
                
     2.5、锁的释放机制
          其实执行lock.unlock()就是释放锁，其底层实现就是每次对myLock对应的hash数据结构里面的加锁次数进行减一，当发现加锁次数是0了，
          说明这个客户端已经不再持有锁了，此时就会执行"del myLock"命令，从redis里删除这个key
          
   
     参考链接：https://blog.csdn.net/shuangyueliao/article/details/89344256
              https://www.cnblogs.com/qdhxhz/p/11046905.html

    两种方案对比：
       Zookeeper
           优点：1、有封装好的框架，容易实现
                2、有等待锁的队列，大大提升抢锁的效率
                
           缺点：每次获取或释放锁都需要动态的创建和删除瞬时节点，相对于redis缓存来说性能没那么高
           
       Redis
           优点：获取和释放锁都是对缓存进行操作，性能较高
           
           缺点：1、实现复杂，需要考虑超时、原子性等情形
                2、没有等待锁的队列，只能在客户端自旋来等待锁，效率低下
                3、redis在哨兵模式下，主节点写入分布式锁，如果此时异步复制给从节点，一旦主节点发生了宕机，出现了主备切换
                   这个时候从节点将会变为主节点，这个时候如果客户端2来尝试加锁，那么也会加锁成功，这样就会导致多个客户端对
                   同一个分布式锁完成了加锁，从而有导致脏数据产生的风险
           
           
           
           
-### redis的主从模式（1个主，多个从）
  1、主从复制，读写分离：1个主服务器，多个从服务器，写入是对主服务器进行操作，并将写入指令同步到多个从服务器，读操作则是从从服务器中读取。
  slaveof no one 让服务器终止复制操作，不再接受主服务器的更新。
  slaveof host port 让服务器复制主服务器的数据，成为该主服务器的从服务器
  
  2、复制的过程：
     2.1、首先从服务器向主服务器发生同步命令
     2.2、主服务器收到命令之后开始执行bgsave命令，与此同时将新接收到的写命令写入到缓冲区
     2.3、bgsave执行结束后，主服务器将快照文件发送给从服务器，与此同时继续将写命令写入到缓冲区
     2.4、从服务器收到快照文件之后，将会丢弃旧的数据，并且解析快照文件
     2.5、主服务器然后将缓冲区的写命令发送给从服务器，从服务器接收到之后开始执行写命令
     2.6、缓冲区写命令发送完毕之后，每执行一个写命令，就向从服务器发送相同的写命令，从服务器接收到之后会执行该写命令
  
     采用复制机制将主服务器数据同步到多个从服务器，然后对每个从服务器设置appendonly yes以及appendfsync everysec来保证从服务器的数据能够已每秒一次的频率持久化到硬盘。
     
     2.7、如何判断写命令已经同步到从服务器，并存入到硬盘？
     是否已经达到从服务器？ 在写入真正数据之后再写入一个唯一的虚构值，然后判断该需虚构值是否存在于从服务器中来判断是否已经达到从服务器，
     是否已经存入到从服务器的硬盘中？ 检查info命令里面的aof_pending_bio_fsync属性值是否为0，如果是则表明已持久化到硬盘
     
   
     优点：
          1、主从模式的一个特点是备份数据，当master节点挂了之后，因为数据有备份，方便恢复
          2、主从模式的另外一个特点是负载均衡，master节点可以进行读写，slave节点只能进行读
     
     缺点：master节点挂了以后，redis就不能对外提供写服务了，因为剩下的slave不能成为master
     
-### redis哨兵（高可用，一个主，多个从，一个哨兵监控集群）
     1.为什么要用到哨兵？
       哨兵主要是为了解决主从架构中出现宕机的情况：
       1.1、从redis宕机
            从redis重启之后会自动加入到redis集群中，并主动从主机同步数据。
       1.2、主redis宕机
            在从redis服务器中执行slave no one命令断开主从关系，并选举一个从服务器升级为主服务器
            将其他从服务器通过slave of命令设置为新的主服务器的从服务器
      
     2.哨兵机制的高可用
        2.1、哨兵机制是解决redis高可用的解决方案：一个哨兵系统由一个或多个哨兵组成，每个哨兵会监视各个redis主服务器以及其对应的从服务器，一旦某个主服务器宕机下线，
             哨兵将会从该主服务器的从服务器中选举一个从服务器升级为主服务器
        2.2、哨兵的定时监控
             2.2.1、对redis集群信息的获取
                    每个哨兵每隔10s会向主节点和从节点发送info命令获取整个集群的拓扑图
             2.2.2、对主节点的判断
                    每个哨兵每隔2s会向redis节点的指定频道发送主节点的判断以及当前哨兵的信息，其他哨兵都订阅了该频道，所以每个哨兵都能感知到其他哨兵对主节点的判断
             2.2.3、判断节点是否宕机的依据
                    每个哨兵每隔1s会向主节点，从节点和其他哨兵发送一次ping命令做一次心跳检查
         2.3、主观下线：
              就是单个哨兵通过心跳检查机制判断某个节点不正常了，宕机了
              
              客观下线：当主观下线的节点是主节点，当前哨兵就会向其他哨兵发送指令通知其他哨兵去对该主节点进行判断，当有其他节点也认为该主节点不正常了，
                        并且认为该主节点不正常的哨兵个数超过选举数量时，哨兵则认为该主节点是客观下线了
                        
         2.4、哨兵leader选举流程：
              当某个哨兵判断某个主节点已经客观下线了，他将会向其他哨兵请求申请自己为故障转移的leader，其他哨兵收到请求之后可以选择同意和不同意
              当同意的哨兵实例数量大于等于（哨兵数量/2+1）时，该哨兵将被选为哨兵leader进行故障转移
              
         2.5、故障转移机制
              2.5.1、哨兵leader将按照如下规则从从节点中选举出新的主节点：
                    1.排除下线的主节点
                    2.选举slave-priority最高的从节点，如果有则返回没有则继续
                    3.选举复制偏移量最大的节点，如果有就返回没有则继续
                    4.选举run_id最小的节点
                    
              2.5.2、更新主从状态：
                     1.首先通过slaveof no one命令让选举出来的从节点成为新的主节点，然后通过slave of命令让其他从节点成为该主节点的从节点
                     2.将下线的主节点设置为新的主节点的从节点，当恢复正常时，重新从主节点复制数据
                     
         优点：相对于主从模式，哨兵模型保证了redis的高可用，当哨兵发现master节点挂掉了以后，就会从slave里面重新选举一个master 
         缺点：只能满足一般生产需求，当数据量过大到一台服务器都存储不下时，这个时候就需要对数据进行分片，将数据存储在多个redis实例中。
         
           参考资料：
           https://www.jianshu.com/p/06ab9daf921d
           https://blog.csdn.net/u012240455/article/details/81843714?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase
           https://www.cnblogs.com/Eugene-Jin/p/10819601.html

-### 基于hash slot（数据分片）算法的redis cluster模式（高可用+高并发，存在hash一致算法以及数据分片算法）
     1、集群架构：
          redis cluster是一个去中心化的集群，每个节点都会跟其他节点保持连接，用来交换彼此的信息，节点加入集群的方式是采用cluster meet命令，meet命令可以让两个节点相互握手，然后通过
          gossip协议交换信息。如果有一个节点node1在集群中，新加入的节点node4与node1进行握手，node1会通过gossip协议将集群中其他节点的信息发送给node4，node4会一一和集群中的其他节点
          握手，然后加入集群之中
         
          节点启动之后会生成一个全局的标致符，在节点与节点握手之后，这些信息也会被持久化下来，节点与节点进行通信，标致符是它唯一的标致
          
          集群数据以数据分布表的形式保存在各个节点上，每个节点会保存一份数据分布表，每个节点会将自己的slot(槽)信息发送给其他节点（为了节省带宽）
          
     2、数据访问
          客户端在初始化的时候只需要知道一个节点的地址即可，客户端首先会先尝试向这个节点去执行命令，比如执行"get key"命令，如果key所在的slot(槽)刚好在这个节点上，则能够直接执行成功，
          如果slot(槽)不在这个节点上，则节点会返回MOVED错误，同时返回该solt(槽)对应的节点信息给客户端，客户端再去正确的节点上执行命令。现在客户端有两种办法去获取数据分布表：
            （1）、一种是客户端每次根据节点返回的MOVED信息在本地缓存slot到节点的映射关系，但是这种做法在初期会经常造成访问两次集群
            （2）、另外一种做法是客户端在收到节点返回的MOVED信息后，通过执行clutser nodes命令去获取数据分布表，一旦数据分布表发生变更，客户端收到节点返回的MOVED错误信息，则会重新
                  去执行cluster nodes命令去更新数据分布表
                  
          当某个key对应的slot（槽）正在发生迁移时客户端去访问这个key时，节点就有可能返回ASK错误，如果key对应的slot(槽)还在迁移源节点上，则能够正常访问，否则节点会返回ASK错误，描述信息会
          返回迁移目的节点的信息，客户端会首先向迁移目的节点发送ASKING命令，然后执行之前的命令。
         
          集群支持hash tags的功能，即可以把一类key定位到同一个slot(槽),redis处理hash tag的逻辑也比较简单，redis只计算从第一次出现{,到第一次出现}中间的substring对应的hash值，
          如果substring是空，则计算整个key的hash值
          
     3、gossip协议通信
        gossip协议包含多种协议的消息：ping,pong,meet,fail等
        (1)meet:meet命令会让新加入的节点与集群中的节点进行握手，从而加入到集群之中
        (2)ping:每个节点都会频繁的给其它节点发送ping消息，用于交换自身维护的元数据信息及状态
        (3)pong:返回ping和meet消息，也可以用于信息广播及更新
        (4)fail:某个节点判断另外一个节点fail之后，就会发送fail消息给其他节点，告知其它节点这个节点下线了
          
     4、故障转移（高可用）
          (1)、判断节点宕机
               在cluster-node-timeout时间内某个master节点一直没有返回pong，那么就是该master就会标记为pfail，类似于哨兵里面master节点主观下线，如果超过一半的master节点都认为该master节点主观下线了的话，那么
               该master节点就被标记为fail,类似于哨兵里面master节点客观下线，则需要重新选举master节点
          (2)、master节点的选举（宕机的master对应的slave会从其他的master拉取选票，票数最多的slave被选为新的master）
               1、检查从节点master主节点的超时时间，如果超时时间大于cluster-node-timeout*cluster-slave-validity-factor,就认为没有资格切换成主节点
               2、然后根据从节点复制master节点的offset对剩余从节点进行排序，offset越大就认为复制的数据越多，则优先选举该从节点
          (3)、更新主从状态
               新master会给集群里面其他的节点发送pong消息，告知自己角色的提升，其他从节点(slave)接着开始复制新的master节点，旧的master节点上线后，会通过gossip协议信息交互，将自己变为
               新的master的slave
          
          
     https://blog.csdn.net/xinzun/article/details/78520986
     https://www.cnblogs.com/mengchunchen/p/10059436.html
     https://blog.csdn.net/liuxiao723846/article/details/86715614?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.control
     https://blog.csdn.net/drdongshiye/article/details/84204392

-### redis cluster的hash一致算法
     当数据量很大时，我们需要对redis进行分库分表操作，将数据均匀的分配到各个redis节点上。
     1.随机分配：查询的时候需要遍历各个redis服务器进行查询，
           缺陷：性能差
     2.使用hash算法进行分配：假设有4台redis服务器，对数据的key进行hash算法的计算并对4求余从而确定某一台redis服务器
                      缺陷：当redis服务器数量发生变化时，很多缓存的位置都会发生变化，也就是说很多缓存在某一定时间内是失效的，缓存数据失效，
                            则会向后台数据库请求数据             
     3.使用一致性hash算法进行分配：
       3.1算法原理:1、一致性hash算法是对2^32-1取模，然后将整个Hash值控件组织成一个虚拟的圆环，构造成一个哈希环
                   整个空间按照顺时针方向组织，圆环的正上方的点代表0,0点右侧第一个点代表1，直到2^32-1,
                   2、接下来将服务器根据IP或者主机名使用一个哈希函数找到其环空间位置
                   3、接下来使用数据的key根据相同的哈希函数定位到环上的某一位置，并从该位置开始，沿顺时针行走，遇到的第一个服务器就是存储该数据的服务器
       3.2一致性hash算法的容错性与扩展性
           容错性：当某一台服务器出现问题，受影响的仅仅是当前问题服务器到前一台服务器（逆时针行走遇到的第一台服务器）的所有数据，其他数据不会受影响
           扩展性：当新增一台服务器时，受影响的仅仅是新增加的这台服务器到前一台服务器（逆时针行走遇到的第一台服务器）的所有数据，其他数据不会受影响
           综上所述：一致性HASH算法对于哈希环上节点的增减，只会影响到环上的一小部分数据，具有较好的容错性和扩展性
       3.3哈希环的数据倾斜问题
           问题：在服务器节点过少时，由于服务器节点分布不均匀导致数据倾斜（被缓存的对象大部分都集中在某一台服务器上）
       解决办法：对每一个服务器节点计算多个hash值，每一个hash位置都放置一个服务节点，称为虚拟节点，然后构造一个虚拟节点到真实节点的映射

-### redis cluster的分片算法
         一个redis集群包括包含16384个哈希槽，redis里面的每个key都属于这16384个哈希槽其中的一个，集群采用CRC16校验算法对key的CRC16校验和并对16384取余得到具体的槽位号，
     集群里面的每个master节点负责处理一部分哈希槽对应的数据，举个例子，一个集群可以有三个节点：
          节点A负责处理0到5500号哈希槽；
          节点B负责处理5501到11000号哈希槽；
          节点C负责处理11000到16384号哈希槽；
     
    hash slot(哈希槽)让(node)的增加和移除变得更简单：
          增加一个master节点，就让其他master对应的hash slot移动部分过去；
          减少一个master节点，就将该master节点对应的hash slot移动到其他master节点上去
          
     优点：任何一个master节点宕机，另外的master节点都不会影响，因为key找的是hash slot而不是节点机器


-### redis的持久化策略
     1、RDB：将某一时刻的数据通过快照的方式保存在磁盘中
       
       1.1、手动触发：
            1.1.1、save命令会阻塞Redis服务器，直到RDB创建快照文件结束，阻塞耗时太长，已废弃
            1.1.2、bgsave命令会fork一个子进程，由子进程来完成快照文件的创建工作，阻塞发生在fork子进程，fork子进程耗时较短
            
       1.2、自动触发：
            1.2.1、配置save选项：save  60 10000，redis从最近一次创建快照开始算起，当60s时间内有10000次写入操作时就会触发bgsave命令
            1.2.2、如果从节点执行全量复制操作，则主节点自动执行bgsave命令生成RDB快照文件并发送给从节点。
            1.2.3、当redis服务器通过SHUTDOWN命令接收到关闭服务器请求时，将会执行save命令
            
       1.3、RDB执行流程：
            1.3.1、执行bgsave首先判断是否存在RDB或AOF的子进程，如果存在，直接返回
            1.3.2、父进程fork操作创建一个子进程，fork操作会阻塞父进程
            1.3.3、fork完成后，子进程开始根据父进程的内存生成临时快照文件，完成后对原有RDB文件进行替换
            1.3.4、子进程完成快照文件的创建和替换工作后会给父进程发送信号，父进程再更新统计信息
            
        1.4、RDB的优缺点：
             优点：
             1.4.1、RDB快照文件是一个紧凑压缩的二进制文件，体积较小
             1.4.2、Redis加载RDB恢复数据远远快于AOF的方式
             缺点：
             1.4.3、redis宕机之后将会丢失最近一次创建快照之后写入的所有数据
             
      2、AOF:以日志的形式记录每一次的写命令，AOF持久化会将被执行的写命令追加到AOF文件的末尾 
         
         2.1、打开aof持久化开关：
              配置appendonly yes
              
         2.2、文件同步策略：通过appendonlysync来控制
              2.2.1、配置为always：每次写入都会同步aof文件，性能太差
              2.2.2、配置为no：由操作系统来决定什么时候对aof文件进行同步，但是redis服务器宕机将会导致不定数量的数据丢失，不安全
              2.2.3、配置为everysec:同时兼顾了安全和性能，每秒同步一次aof文件，最多只会丢失一秒钟的数据
              
         2.3、AOF执行流程
              2.3.1、命令写入：将写命令写入到aof缓冲区。（为啥要写入到缓冲区，如果每次写aof命令都直接追加到硬盘，那么性能完全取决于当前硬盘负载）
              2.3.2、文件同步：将缓存区的写命令同步到硬盘，同步策略策略参考2.2
              2.3.3、文件重写：随着写命令的不断追加，aof文件体积将会越来越大，因此引入重写机制压缩文件体积
                     手动触发重写操作：执行bgrewriteaof命令
                     自动触发重写操作：通过设置auto-aof-rewrite-percentage（aof文件空间与上一次重写后的文件空间的比值）选项和auto-aof-rewrite-min-size（aof重写时最小体积）选项
                     例如：auto-aof-rewrite-percentage设置为100，auto-aof-rewrite-min-size设置为64mb，那么当aof文件体积大于64mb，并且aof文件比上次重写后的aof文件体积大了至少一倍
                     时，redis将会自动执行bgrewriteaof命令。
              
                    重写之后文件为啥会变小：
                    1、内存里面已经超时的数据不会再次写入aof文件中
                    2、旧的aof文件含有无效的数据
                    3、多条写命令可以合并为一个
                    
                    文件重写流程：
                    1、执行bgrewriteaof命令，判断是否存在aof子进程，如果存在直接返回
                    2、父进程执行fork操作创建一个子进程，子进程则进行重写操作（重写是根据内存中的数据生成对应的写命令并写入到新的aof文件中）
                    3、父进程继续响应写命令，一边将写命令写入到旧的aof文件中，防止重写失败导致数据丢失，一边将写命令写入到缓存区
                    4、子进程重写结束后，将会给父进程发送信号，父进程接收到信号后将会把缓冲区的写命令追加到新的aof文件
              
         2.4、aof的优缺点：
              优点：当采用每秒进行一次同步时，redis宕机之后最多丢失一秒钟的数据，并且此时redis仍能保持较好的性能
              缺点：2.4.1、aof文件体积一般要大于RDB
                   2.4.2、数据恢复速度相对于RDB也比较慢
                   
                   
      3、性能问题及解决方案：
         RDB创建快照以及AOF重写都会fork子进程，造成redis的阻塞，为了不影响主进程响应，我们需要尽可能降低阻塞
         3.1、降低fork操作频率，如适度放宽AOF自动触发机制
         3.2、控制redis最大可用内存，fork耗时与内存量成正比
              
                     
                    
            

